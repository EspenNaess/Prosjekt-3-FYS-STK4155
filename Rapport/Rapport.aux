\relax 
\catcode `"\active 
\abx@aux@sortscheme{nty}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{nynorsk}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{nynorsk}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{nynorsk}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{nynorsk}}
\abx@aux@cite{Epil}
\abx@aux@cite{Epil2}
\abx@aux@cite{Epil3}
\abx@aux@cite{Epil4}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduksjon}{1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\abx@aux@cite{Naess}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Teori og metodar}{2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Oppsett av data}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Episignal}{{2.1a}{3}}
\newlabel{sub@Episignal}{{a}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Eigenskapsuttrekking ved PCA}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}St\IeC {\o }ttevektormaskiner (SVM)}{6}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Her er $c_{+}$ og $c_{-}$ forventningsverdiane for kvar si fordeling over features knytte til kvar av dei to klassene som det skal klassifiserast til. Det vert definert ei line\IeC {\ae }r avgjerdsgrense som st\IeC {\r a}r vertikalt p\IeC {\r a} vektoren $w=c_{+}-c_{-}$ som svarar til den stripla linja i biletet. Her er $x$ eit nytt sampel ein \IeC {\o }nskjer \IeC {\r a} klassifisera. Ut i fr\IeC {\r a} dette viser det seg at ein kan motivera nytta til st\IeC {\o }ttevektormaskiner.\relax }}{6}}
\newlabel{SVM}{{2.2}{6}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces M\IeC {\r a}let er \IeC {\r a} finna avstanden fr\IeC {\r a} eit sampel x til avgjerdsgrensa. Grafisk gjev det meining \IeC {\r a} prosjektera p\IeC {\r a} w og henta ut lengda av denne projekterte vektoren, d\IeC {\r a} w vil alltid vera ortogonal til avgjerdsgrensa $g(x)=0$.\relax }}{7}}
\newlabel{SVMmath}{{2.3}{7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Eit sampel x vert klassifisert til ei klasse basert p\IeC {\r a} om $w^Tx + b>1$ eller $w^Tx + b<1$. Dette gjev to nye grensevektorar som vert kalla st\IeC {\o }ttevektorar som h\IeC {\o }vesvis er gjevne ved $w^Tx + b=1$ og $w^Tx + b=-1$. Intuitivt kan ein tenkja p\IeC {\r a} st\IeC {\o }ttevektorane som ein veg. Marginen er lengda p\IeC {\r a} vegen medan avgjerdsgrensa er delelinja p\IeC {\r a} vegen. Ein fors\IeC {\o }kjer \IeC {\r a} byggja ein veg som er s\IeC {\r a} brei som mogleg mellom datapunkta, alts\IeC {\r a} s\IeC {\r a} stor margin som mogleg. Ut i fr\IeC {\r a} likningane vil ein margin vera p\IeC {\r a} 2 d\IeC {\r a} st\IeC {\o }ttevektorane femner verdiar fr\IeC {\r a} -1 til 1. Ein m\IeC {\r a} samstundes normalisera med lengda til w, s\IeC {\r a} marginen vert $\frac  {2}{||w||}$.\relax }}{8}}
\newlabel{SVMbilete}{{2.4}{8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {a)}SVM for ikkje-line\IeC {\ae }rt separable datamengder}{9}}
\abx@aux@cite{Sergios}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {b)}L\IeC {\o }ysing av optimeringsproblem for SVMar}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {c)}Kerneltrikset}{11}}
\abx@aux@cite{Goodfellow-et-al-2016}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Avbildinga $\phi $ i ein generell kernelfunksjon vert gjord indirekte i kernelfunksjonen med m\IeC {\r a}l om \IeC {\r a} transformera datamengda til eit nytt indreproduktrom der avgjerdsgrensa vert line\IeC {\ae }r.\relax }}{12}}
\newlabel{kerneltrick}{{2.5}{12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Recurrent Neural Networks (RNN)}{12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {a)}Long Short-Term Memory RNN (LSTM)}{13}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces LSTM si l\IeC {\o }ysing p\IeC {\r a} problema knytte til ein vanleg RNN er \IeC {\r a} introdusera tre portar som kontrollerer oppdatering av minne; ein inputport, ein \IeC {\guillemotleft }forget\IeC {\guillemotright }-port og ein outputport. Inputporten og outputporten avgjer h\IeC {\o }vesvis kva som skal vera input og output for minnestrukturen. \IeC {\guillemotleft }forget\IeC {\guillemotright }-porten avgjer kva som skal gl\IeC {\o }ymast i minnestrukturen. Saman kontrollerer dei at ingen gradientar eksploderer i verdi eller kverv mot 0.\relax }}{13}}
\newlabel{LSTMcell}{{2.6}{13}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Resultat}{14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Resultat for eigenskapsuttrekking ved PCA}{14}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Resultat for logistisk regresjon}{15}}
\newlabel{LRL2}{{3.1a}{15}}
\newlabel{sub@LRL2}{{a}{15}}
\newlabel{LRL1}{{3.2a}{15}}
\newlabel{sub@LRL1}{{a}{15}}
\newlabel{LRPlot}{{3.3a}{16}}
\newlabel{sub@LRPlot}{{a}{16}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Resultat for SVM}{17}}
\newlabel{linear}{{3.4a}{17}}
\newlabel{sub@linear}{{a}{17}}
\newlabel{poly}{{3.5a}{18}}
\newlabel{sub@poly}{{a}{18}}
\newlabel{rbf}{{3.6a}{18}}
\newlabel{sub@rbf}{{a}{18}}
\newlabel{sigmoid}{{3.7a}{19}}
\newlabel{sub@sigmoid}{{a}{19}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Resultat for MLPar}{19}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Dei beste oppn\IeC {\r a}dde resultata med sj\IeC {\o }lvimplementert nevralt nettverk fr\IeC {\r a} prosjekt 2. Kolonnen \IeC {\guillemotleft }Nerveceller\IeC {\guillemotright } gjev for kvar k\IeC {\o }yring ein array med talet p\IeC {\r a} nerveceller for lag l gjeve ved indeks l i arrayen. \relax }}{19}}
\newlabel{bestMLPs}{{3.8}{19}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Dei same parametrane som i Fig. ~\ref  {bestMLPs} k\IeC {\o }yrde med keras si implementering av MLPar og Adamoptimizeren. Kolonnen \IeC {\guillemotleft }Nerveceller\IeC {\guillemotright } gjev for kvar k\IeC {\o }yring ein array med talet p\IeC {\r a} nerveceller for lag l gjeve ved indeks l i arrayen. \relax }}{20}}
\newlabel{bestMLPsKeras}{{3.9}{20}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Det beste resultatet for MLPar med omsyn p\IeC {\r a} ymse prosentdelar av den totale treningsmengda. Det er tydeleg at det med MLPar framleis vert s\IeC {\ae }rs gode resultat tross i ei redusert treningsmengde. Kolonnen \IeC {\guillemotleft }Nerveceller\IeC {\guillemotright } gjev for kvar k\IeC {\o }yring ein array med talet p\IeC {\r a} nerveceller for lag l gjeve ved indeks l i arrayen. \relax }}{20}}
\newlabel{bestMLPsYmse}{{3.10}{20}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.5}Resultat for LSTMar}{20}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Beste oppn\IeC {\r a}dde resultat for keras sin LSTM. Etter kring 35 minutt vil grannsemda liggja stabilt p\IeC {\r a} minst $0.93$, men vidare g\IeC {\r a}r det veldig treigt. Etter over 4 timar l\IeC {\r a}g grannsemda stabilt over 0.96. Det siste laget er alltid eit densely-connected lag, medan dei andre er LSTM-lag. Kolonnen \IeC {\guillemotleft }Nerveceller\IeC {\guillemotright } gjev for kvar k\IeC {\o }yring ein array med talet p\IeC {\r a} nerveceller for lag l gjeve ved indeks l i arrayen.\relax }}{20}}
\newlabel{bestLSTMs}{{3.11}{20}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Det beste resultatet for LSTMar med omsyn p\IeC {\r a} ymse prosentdelar av den totale treningsmengda. Samanlikna med tidlegare tabell Fig. \ref  {bestMLPsYmse} s\IeC {\r a} vert det tydeleg at b\IeC {\r a}de MLPar og LSTMar framleis gjev gode resultat sj\IeC {\o }lv med ei s\IeC {\ae }rs redusert treningsmengde. Kolonnen \IeC {\guillemotleft }Nerveceller\IeC {\guillemotright } gjev for kvar k\IeC {\o }yring ein array med talet p\IeC {\r a} nerveceller for lag l gjeve ved indeks l i arrayen. \relax }}{21}}
\newlabel{bestLSTMs}{{3.12}{21}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.6}Filstruktur for koden}{21}}
\abx@aux@cite{DWT}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Perspektiv og konklusjonar}{22}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Vedheng}{24}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Utvalde k\IeC {\o }yringar med scikit-learn si MLP implementering. Det vart nytta dei same parametrane som i Fig. ~\ref  {bestMLPs} og Fig. ~\ref  {bestMLPsKeras}. Kolonnen \IeC {\guillemotleft }Nerveceller\IeC {\guillemotright } gjev for kvar k\IeC {\o }yring ein array med talet p\IeC {\r a} nerveceller for lag l gjeve ved indeks l i arrayen. \relax }}{24}}
\newlabel{bestMLPsSkikit}{{5.1}{24}}
